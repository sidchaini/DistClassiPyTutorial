{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![colab-button](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sidchaini/DistClassiPyTutorial/blob/main/tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "[![github-badge](https://img.shields.io/badge/GitHub-sidchaini/DistClassiPyTutorial-blue)](https://github.com/sidchaini/DistClassiPyTutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leveraging Distance Metrics for Better Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Siddharth Chaini, 6th January, 2025**\n",
    "\n",
    "(Special thanks to Federica Bianco, Ashish Mahabal and Ajit Kembhavi!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This hands-on session is largely based on and derived from the work described in [Chaini et. al 2024](https://arxiv.org/abs/2403.12120). It will go over:\n",
    "1. What are distance metrics?\n",
    "2. Where are they used in machine learning?\n",
    "3. DistClassiPy\n",
    "    - Demo on a real astronomical dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### 0. Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let us first install DistClassiPy from PyPI. I am installing 0.2.1, the latest as of 2025-01-05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "ZZ5CAUOfHwO4",
    "outputId": "d49967a0-e20f-497b-b5f4-bfb4e138d628",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install distclassipy==0.2.1 # latest as of 2025-01-05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title\n",
    "%%capture\n",
    "!wget https://github.com/sidchaini/DistClassiPyTutorial/archive/refs/heads/main.zip\n",
    "!unzip main.zip\n",
    "!mv DistClassiPyTutorial-main/* .\n",
    "!rm -rf main.zip DistClassiPyTutorial-main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9GC3xlkMQu-Z"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "import pandas as pd\n",
    "import distclassipy as dcpy\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print(f\"distclassipy version {dcpy.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What are distance metrics?\n",
    "\n",
    "**Definition**: A distance is a quantity that tells us how similar two objects are. It follows the axioms:\n",
    "1. *Identity of indiscernibles*: $$d(x, y)=0 \\iff x=y $$\n",
    "2. *Symmetry*: $$d(x, y)=d(y, x)$$\n",
    "3. *Triangle inequality*: $$d(x, y)\\leq d(x, z) + d(z, y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Small exercise**: Which of the following is a distance metric, and which is not? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_fn1(x, y):\n",
    "    return np.sum(np.abs(x - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_fn2(x, y):\n",
    "    return (1 + np.sum(np.abs(x - y)))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing 2D distance metric spaces**: We can plot the locus of a central point (*e.g.,*$(5,5)$) in a given two dimensional space. The locus appear as contour lines, which can illustrate geometry of the space when plotted in Euclidean space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Distances in Machine Learning\n",
    "\n",
    "Distance metrics power different ML tasks:\n",
    "\n",
    "- **Clustering**: Distance metrics help group similar data points (e.g., K-Means, Hierarchical Clustering).\n",
    "- **Dimensionality Reduction**: They preserve data structure in fewer dimensions (e.g., PCA, t-SNE).\n",
    "- **Classification**: They determine proximity for decision-making (e.g., K-Nearest Neighbors, SVM, **DistClassiPy**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title\n",
    "from IPython.display import Video\n",
    "Video(\n",
    "    \"https://sidchaini.github.io/videos/distclassipy.mp4\", \n",
    "    width=480, height=240\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. DistClassiPy for ZTF Light Curve Classification\n",
    "\n",
    "For this example, we will be using data from \"The ZTF Source Classification Project: III. A Catalog of Variable Sources\" through which they have made available on Zenodo.\n",
    "\n",
    "[![zenodo-badge](https://zenodo.org/badge/DOI/10.5281/zenodo.14155156.svg)](https://zenodo.org/records/14155156)\n",
    "\n",
    "I downloaded and downsampled them to choose 4000 objects from 4 classes of variable stars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of simplicity, let us focus on three features from the complete ZTF SCoPE features (refer to [Healy et al. 2024](https://arxiv.org/abs/2312.00143) for more details):\n",
    "- ```inv_vonneumannratio```: Inverse of von Neumann ratio ([von Neumann 1941](https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-12/issue-4/Distribution-of-the-Ratio-of-the-Mean-Square-Successive-Difference/10.1214/aoms/1177731677.full), [1942](https://projecteuclid.org/journals/annals-of-mathematical-statistics/volume-13/issue-1/A-Further-Remark-Concerning-the-Distribution-of-the-Ratio-of/10.1214/aoms/1177731645.full)), which is the ratio of correlated variance and variance - it detects non-randomness, and a high value implies periodic behaviour.\n",
    "- ```norm_peak_to_peak_amp```: Normalized peak-to-peak amplitude [(Sokolovsky et al. 2009)](https://arxiv.org/abs/0901.1064) - it tells us about the source brightness.\n",
    "- ```stetson_k```: Stetson K coefficient ([Stetson 1996](https://iopscience.iop.org/article/10.1086/133808/meta?casa_token=EMo0hxKqIkUAAAAA:b8y8ONGzEQAJq2WJfrCASQt_FMw7HX_h7i-VChDbTYc1ShDkEih4I2Sm184VFLTS1UpDbATGN8GPmTY4YXRG87jP2Q)) is related to the observed scatter - it tells us about the light curve shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title\n",
    "df = features.loc[:, feature_names]\n",
    "df[\"class\"] = labels[\"class\"]\n",
    "sns.pairplot(df, hue=\"class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title\n",
    "X = features.loc[:, feature_names].to_numpy()\n",
    "y = labels.to_numpy().ravel()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title\n",
    "acc = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred, average=\"macro\")\n",
    "\n",
    "print(f\"Accuracy = {acc:.3f}\")\n",
    "print(f\"F1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using multiple distance metrics together!\n",
    "\n",
    "We can combine multiple distance metrics together!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 1**: Keeping the same set of features, vary the distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_clf = ...\n",
    "ensemble_clf.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ensemble = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title\n",
    "acc = accuracy_score(y_true=y_test, y_pred=y_pred_ensemble)\n",
    "f1 = f1_score(y_true=y_test, y_pred=y_pred_ensemble, average=\"macro\")\n",
    "\n",
    "print(f\"Accuracy = {acc:.3f}\")\n",
    "print(f\"F1 = {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title\n",
    "sns.heatmap(\n",
    "    ensemble_clf.quantile_scores_df_.drop_duplicates(), annot=True, cmap=\"Blues\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance improves, but not by a lot.\n",
    "\n",
    "But what if we also allowed each metric to work with different features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 2**: Varying the features AND the distance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our work, we found:\n",
    "- ```We can select a distance metric that works best based on the object of interest!```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title\n",
    "from IPython.display import Image\n",
    "Image(url=\"https://arxiv.org/html/2403.12120v2/x31.png\",width=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance improvement here is much more significant!\n",
    "\n",
    "If you are interested in more details:\n",
    "\n",
    "[![arxiv-badge](https://img.shields.io/badge/arXiv-2403.12120-red)](https://arxiv.org/abs/2403.12120)\n",
    "[![github-badge](https://img.shields.io/badge/GitHub-sidchaini/LightCurveDistanceClassification-blue)](https://github.com/sidchaini/LightCurveDistanceClassification)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM7Z9RCnKuC6XRx+E5OPsey",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
